{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Define the path to the COCO JSON file\n",
    "coco_json_file = \"bigData1/labels.json\"\n",
    "\n",
    "# Load the COCO JSON file\n",
    "with open(coco_json_file, \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "category_counts = []\n",
    "\n",
    "# Update the category IDs\n",
    "for category in coco_data[\"categories\"]:\n",
    "    category_counts.append({\"id\": category[\"id\"], \"name\": category[\"name\"], \"count\": 0})\n",
    "\n",
    "# Update the category IDs in the annotations\n",
    "for annotation in coco_data[\"annotations\"]:\n",
    "    for category in category_counts:\n",
    "        if category[\"id\"] == annotation[\"category_id\"]:\n",
    "            category[\"count\"] += 1\n",
    "\n",
    "# Save the updated COCO JSON file\n",
    "with open(\"category_counts.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"id\", \"name\", \"count\"])\n",
    "    for category in category_counts:\n",
    "        writer.writerow([category[\"id\"], category[\"name\"], category[\"count\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the two tables into pandas dataframes\n",
    "df1 = pd.read_csv(\"category_counts.csv\")\n",
    "df2 = pd.read_csv(\"quaily.csv\")\n",
    "\n",
    "\n",
    "# Perform a left join on the \"name\" column\n",
    "result = pd.merge(df1, df2, on=\"name\", how=\"left\")\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result.to_csv(\"combined_table.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fiftyone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfiftyone\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mfo\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#load a dataset inside the dataset1 directory the data is of type coco\u001b[39;00m\n\u001b[1;32m      4\u001b[0m dataset \u001b[39m=\u001b[39m fo\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_dir(\n\u001b[1;32m      5\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mthoma\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGithub\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFoocus-Logodetection\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mbigData1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     fo\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mCOCODetectionDataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fiftyone'"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "#load a dataset inside the dataset1 directory the data is of type coco\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    r\"C:\\Users\\thoma\\Documents\\Github\\Foocus-Logodetection\\bigData1\",\n",
    "    fo.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    annotation_path=\"labels.json\"  # Add this line\n",
    "\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taining_dataset = fo.Dataset.from_dir(\n",
    "    r\"C:\\Users\\thoma\\Documents\\Github\\Foocus-Logodetection\\dataset\",\n",
    "    fo.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    annotation_path=\"train.json\"  # Add this line\n",
    ")\n",
    "\n",
    "session = fo.launch_app(taining_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = fo.Dataset.from_dir(\n",
    "    r\"C:\\Users\\thoma\\Documents\\Github\\Foocus-Logodetection\\dataset\",\n",
    "    fo.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\",\n",
    "    annotation_path=\"mvpDataset.json\"  # Add this line\n",
    ")\n",
    "\n",
    "session = fo.launch_app(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "resnet50(weights=ResNet50_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)\n",
    "\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
